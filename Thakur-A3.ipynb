{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3: A\\*, IDS, and Effective Branching Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prashant Kumar Thakur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, I have implemented the Recursive Best-First Search\n",
    "implementation of the A\\* algorithm given in class with minor modification of code provided in the class notebook.  The functions are named as per the requirement of the assignment and kept in original form.  An additional function `ebf` has been defined that returns an estimate of the effective branching factor for a search algorithm applied to a search problem.\n",
    "\n",
    "So, the required functions are\n",
    "\n",
    "   - `aStarSearch(startState, actionsF, takeActionF, goalTestF, hF)`\n",
    "   - `iterativeDeepeningSearch(startState, goalState, actionsF, takeActionF, maxDepth)`\n",
    "   - `ebf(nNodes, depth, precision=0.01)`, returns number of nodes expanded and depth reached during a search.\n",
    "\n",
    "The function `iterativeDeepeningSearch` and `aStarSearch` were applied to several eight-tile sliding puzzle\n",
    "problems. The following functions were also taken from the professors solution code for Assignment 2 with minor modification to handle the requirement of A\\* function:\n",
    "\n",
    "  * `actionsF_8p(state)`: returns a list of up to four valid actions that can be applied in `state`. With each action include a step cost of 1. For example, if all four actions are possible from this state, return [('left', 1), ('right', 1), ('up', 1), ('down', 1)].\n",
    "  * `takeActionF_8p(state, action)`: return the state that results from applying `action` in `state` and the cost of the one step,\n",
    "  \n",
    "plus the following function for the eight-tile puzzle to check if the current state equals the goal state:\n",
    "\n",
    "  * `goalTestF_8p(state, goal)`\n",
    "  \n",
    "The following function has been implemented as per the requirement and the results are discussed inline.\n",
    "\n",
    "   - runExperiment(goalState1, goalState2, goalState3, [h1, h2, h3])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Functions\n",
    "\n",
    "For `aStarSearch` use the following two heuristic functions, plus one more of my own design, for a total of three heuristic functions.\n",
    "\n",
    "  * `h1_8p(state, goal)`: $h(state, goal) = 0$, for all states $state$ and all goal states $goal$,\n",
    "  * `h2_8p(state, goal)`: $h(state, goal) = m$, where $m$ is the Manhattan distance that the blank is from its goal position,\n",
    "  * `h3_8p(state, goal)`: $h(state, goal) = ?$, Similar to h2_8p but instead of returning the Manhattan distance of only blank space, total number of misplaced tiles are considered to compute the aggregate Manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply all four algorithms (`iterativeDeepeningSearch` plus `aStarSearch` with the three heuristic\n",
    "functions) to three eight-tile puzzle problems with start state\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "1 & 2 & 3\\\\\n",
    "4 & 0 & 5\\\\\n",
    "6 & 7 & 8\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "and these three goal states.\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccccccccc}\n",
    "1 & 2 & 3  & ~~~~ & 1 & 2 & 3  &  ~~~~ & 1 & 0 &  3\\\\\n",
    "4 & 0 & 5  & & 4 & 5 & 8  & & 4 & 5 & 8\\\\\n",
    "6 & 7 & 8 &  & 6 & 0 & 7  & & 2 & 6 & 7\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a well-formatted table like the following.\n",
    "\n",
    "           [1, 2, 3, 4, 0, 5, 6, 7, 8]    [1, 2, 3, 4, 5, 8, 6, 0, 7]    [1, 0, 3, 4, 5, 8, 2, 6, 7] \n",
    "    Algorithm    Depth  Nodes  EBF              Depth  Nodes  EBF              Depth  Nodes  EBF          \n",
    "         IDS       0      0  0.000                3     43  3.086               11 225850  2.954         \n",
    "        A*h1       0      0  0.000                3    116  4.488               11 643246  3.263         \n",
    "        A*h2       0      0  0.000                3     51  3.297               11 100046  2.733         \n",
    "\n",
    "This representation has been discussed below the code description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt, ceil\n",
    "class Node:\n",
    "    def __init__(self, state, f=0, g=0,h=0):\n",
    "        self.state = state\n",
    "        self.f = f\n",
    "        self.g = g\n",
    "        self.h = h\n",
    "    def __repr__(self):\n",
    "        return \"Node(\" + repr(self.state) + \", f=\" + repr(self.f) + \\\n",
    "               \", g=\" + repr(self.g) + \", h=\" + repr(self.h) + \")\"\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "# IDS and DS\n",
    "def iterativeDeepeningSearch(startState, goalState,actionsF, takeActionF, maxDepth):\n",
    "    global nNode\n",
    "    nNode = [0,0]  # [depth,nodes]\n",
    "    for depth in range(maxDepth):\n",
    "        result = depthLimitedSearch(startState, goalState,actionsF, takeActionF, depth)\n",
    "        if result is 'failure':\n",
    "            return 'failure'\n",
    "        if result is not 'cutoff':\n",
    "            result.insert(0, startState)\n",
    "            return (result)\n",
    "    return 'cutoff'\n",
    "\n",
    "\n",
    "def depthLimitedSearch(state, goalState,actionsF, takeActionF, depthLimit):\n",
    "#     global nNode\n",
    "    if state == goalState:\n",
    "        return []\n",
    "    if depthLimit == 0:\n",
    "        return 'cutoff'\n",
    "    cutoffOccurred = False\n",
    "    for action in actionsF(state):\n",
    "        # Find all expanded nodes\n",
    "        nNode[1] +=1\n",
    "        childState,_= takeActionF(state, action)\n",
    "        result = depthLimitedSearch(childState, goalState,actionsF, takeActionF, depthLimit-1)\n",
    "        if result is 'cutoff':\n",
    "            cutoffOccurred = True\n",
    "        elif result is not 'failure':\n",
    "            # Find total depth\n",
    "            nNode[0]+=1\n",
    "            result.insert(0, childState)\n",
    "            return result\n",
    "    if cutoffOccurred:\n",
    "        return 'cutoff'\n",
    "    else:\n",
    "        return 'failure'\n",
    "\n",
    "\n",
    "# End of IDS and DS\n",
    "#####################################################################################\n",
    "# A-start start\n",
    "def aStarSearch(startState, actionsF, takeActionF, goalTestF, hF):\n",
    "    global aNode\n",
    "    aNode = [0,0] # [depth,nodes]\n",
    "    h = hF(startState)\n",
    "    startNode = Node(state=startState, f=0+h, g=0, h=h)\n",
    "    return aStarSearchHelper(startNode, actionsF, takeActionF, goalTestF, hF, float('inf'))\n",
    "\n",
    "\n",
    "def aStarSearchHelper(parentNode, actionsF, takeActionF, goalTestF, hF, fmax):\n",
    "    if goalTestF(parentNode.state):\n",
    "        return ([parentNode.state], parentNode.g)\n",
    "    ## Construct list of children nodes with f, g, and h values\n",
    "    actions = actionsF(parentNode.state)\n",
    "    if not actions:\n",
    "        return (\"failure\", float('inf'))\n",
    "    children = []\n",
    "    for action in actions:\n",
    "        # Find all expanded nodes\n",
    "        aNode[1] += 1\n",
    "        (childState,stepCost) = takeActionF(parentNode.state, action)\n",
    "        h = hF(childState)\n",
    "        g = parentNode.g + stepCost\n",
    "        f = max(h+g, parentNode.f)\n",
    "        childNode = Node(state=childState, f=f, g=g, h=h)\n",
    "        children.append(childNode)\n",
    "    while True:\n",
    "        # find best child\n",
    "        children.sort(key = lambda n: n.f) # sort by f value\n",
    "        bestChild = children[0]\n",
    "        if bestChild.f > fmax or bestChild.f == float('inf'):\n",
    "            return (\"failure\",bestChild.f)\n",
    "        # next lowest f value\n",
    "        alternativef = children[1].f if len(children) > 1 else float('inf')\n",
    "        # expand best child, reassign its f value to be returned value\n",
    "        result,bestChild.f = aStarSearchHelper(bestChild, actionsF, takeActionF, goalTestF,\n",
    "                                            hF, min(fmax,alternativef))\n",
    "        if result is not \"failure\":\n",
    "            # Gives depth of search\n",
    "            aNode[0] += 1\n",
    "            result.insert(0,parentNode.state)\n",
    "            return (result, bestChild.f)\n",
    "\n",
    "#End of A-Start\n",
    "######################################################################\n",
    "# Eight Puzzle\n",
    "\n",
    "\n",
    "def findBlank_8p(s):\n",
    "    return iTorc(s.index(0))\n",
    "\n",
    "\n",
    "def actionsF_8p(state):\n",
    "    r, c = findBlank_8p(state)\n",
    "    actions = []\n",
    "    if c > 0:\n",
    "        actions.append(('left',1))\n",
    "    if c < 2:\n",
    "        actions.append(('right',1))\n",
    "    if r > 0:\n",
    "        actions.append(('up',1))\n",
    "    if r < 2:\n",
    "        actions.append(('down',1))\n",
    "    return actions\n",
    "\n",
    "\n",
    "def takeActionF_8p(state, action):\n",
    "    import copy\n",
    "    # action passed has (actual_action, cost)\n",
    "    action,cost = action\n",
    "    state = copy.deepcopy(state)\n",
    "    r, c = findBlank_8p(state)\n",
    "    dr = dc = 0\n",
    "    if action is 'left':\n",
    "        dc -= 1\n",
    "    elif action is 'right':\n",
    "        dc += 1\n",
    "    elif action is 'up':\n",
    "        dr -= 1\n",
    "    elif action is 'down':\n",
    "        dr += 1\n",
    "    newr, newc = r+dr, c+dc\n",
    "    setTile(state, r, c, getTile(state, newr, newc))\n",
    "    setTile(state, newr, newc, 0)\n",
    "    return (state,cost)\n",
    "\n",
    "\n",
    "def goalTestF_8p(s, goalState):\n",
    "    return s == goalState\n",
    "\n",
    "def rcToi(row, col):\n",
    "    return row*3+col\n",
    "\n",
    "\n",
    "def iTorc(i):\n",
    "    row = i // 3\n",
    "    col = i - row*3\n",
    "    return (row, col)\n",
    "\n",
    "def setTile(state, row, col, tile):\n",
    "    state[rcToi(row, col)] = tile\n",
    "    return state\n",
    "\n",
    "def getTile(state, row, col):\n",
    "    return state[rcToi(row, col)]\n",
    "# End of 8-puzzle\n",
    "\n",
    "###################################################\n",
    "# Heuristic, EBF and runExperiment\n",
    "def h1_8p(state,goal):\n",
    "    return 0\n",
    "\n",
    "#Manhattan distance of blank space only\n",
    "def h2_8p(state,goal):\n",
    "    sc = findBlank_8p(state)\n",
    "    gc = findBlank_8p(goal)\n",
    "    dist = abs(gc[0]-sc[0])+abs(gc[1]-sc[1])\n",
    "    return dist\n",
    "\n",
    "#Ecludian distance of blank space\n",
    "def h4_8p(state,goal):\n",
    "    sx,sy = findBlank_8p(state)\n",
    "    gx,gy = findBlank_8p(goal)\n",
    "    return ceil(sqrt((gx-sx)**2+(gy-sy)**2))\n",
    "\n",
    "\n",
    "# Manhattan distance - sum of all misplaced values\n",
    "def h3_8p(state,goal):\n",
    "    sum = 0\n",
    "    for item in state:\n",
    "        sc = iTorc(state.index(item))\n",
    "        gc = iTorc(goal.index(item))\n",
    "        if sc != gc and item != 0:\n",
    "            sum += abs(sc[0]-gc[0])+abs(sc[1]-gc[1])\n",
    "    return sum\n",
    "\n",
    "def eqn_sum(c,d):\n",
    "    sum = 1\n",
    "    while d != 0:\n",
    "        sum += c**(d)\n",
    "        d = d-1\n",
    "    return sum\n",
    "\n",
    "def ebf(N,d,precision=0.01):\n",
    "    if N <=0:\n",
    "        return 0.0\n",
    "    low = 0.0\n",
    "    high = N\n",
    "    mid = float(high)\n",
    "    while abs(eqn_sum(mid,d)-N) > precision:\n",
    "        mid = (low+high)/2.0\n",
    "        if eqn_sum(mid,d) > N:\n",
    "            high = mid\n",
    "        else:\n",
    "            low = mid\n",
    "    return mid\n",
    "\n",
    "def runExperiment(goalState1, goalState2, goalState3,h):\n",
    "    # Start state of each function\n",
    "    state = [1,2,3,4,0,5,6,7,8]\n",
    "    # MAX DEPTH OF IDS\n",
    "    max_depth = 15\n",
    "    print('\\t{}\\t{}\\t{}\\n'.format(goalState1,goalState2,goalState3))\n",
    "    print('{}{:>10}{:>7}{:>8}{:>15}{:>10}{:>8}{:>15}{:>10}{:>8}'.format('Algorithm','Depth','Nodes','EBF','Depth','Nodes','EBF','Depth','Nodes','EBF'))\n",
    "    value_ids=[\"IDS\"]\n",
    "    value_as ={'h1_8p':[\"A*h1\"], 'h2_8p':[\"A*h2\"],'h3_8p':[\"A*h3\"]}\n",
    "    for i in [goalState1,goalState2,goalState3]:\n",
    "        iterativeDeepeningSearch(state, i, actionsF_8p, takeActionF_8p, maxDepth=max_depth)\n",
    "        value_ids.extend(nNode)\n",
    "        value_ids.append(ebf(nNode[1],nNode[0]))\n",
    "        for hf in h:\n",
    "            aStarSearch(state, actionsF_8p, takeActionF_8p, lambda s: goalTestF_8p(s, i),lambda s: hf(s, i))\n",
    "            value_as[hf.__name__].extend(aNode)\n",
    "            value_as[hf.__name__].append(ebf(aNode[1],aNode[0]))\n",
    "    print('{}\\t\\t{}\\t{}\\t{:.3f}\\t\\t{}\\t{}\\t{:.3f}\\t\\t{}\\t{}\\t{:.3f}'.format(value_ids[0],value_ids[1],value_ids[2],value_ids[3],value_ids[4],value_ids[5],value_ids[6],value_ids[7],value_ids[8],value_ids[9]))\n",
    "    print('{}\\t\\t{}\\t{}\\t{:.3f}\\t\\t{}\\t{}\\t{:.3f}\\t\\t{}\\t{}\\t{:.3f}'.format(value_as['h1_8p'][0],value_as['h1_8p'][1],value_as['h1_8p'][2],value_as['h1_8p'][3],value_as['h1_8p'][4],value_as['h1_8p'][5],value_as['h1_8p'][6],value_as['h1_8p'][7],value_as['h1_8p'][8],value_as['h1_8p'][9]))\n",
    "    print('{}\\t\\t{}\\t{}\\t{:.3f}\\t\\t{}\\t{}\\t{:.3f}\\t\\t{}\\t{}\\t{:.3f}'.format(value_as['h2_8p'][0],value_as['h2_8p'][1],value_as['h2_8p'][2],value_as['h2_8p'][3],value_as['h2_8p'][4],value_as['h2_8p'][5],value_as['h2_8p'][6],value_as['h2_8p'][7],value_as['h2_8p'][8],value_as['h2_8p'][9]))\n",
    "    print('{}\\t\\t{}\\t{}\\t{:.3f}\\t\\t{}\\t{}\\t{:.3f}\\t\\t{}\\t{}\\t{:.3f}'.format(value_as['h3_8p'][0],value_as['h3_8p'][1],value_as['h3_8p'][2],value_as['h3_8p'][3],value_as['h3_8p'][4],value_as['h3_8p'][5],value_as['h3_8p'][6],value_as['h3_8p'][7],value_as['h3_8p'][8],value_as['h3_8p'][9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[1, 2, 3, 4, 0, 5, 6, 7, 8]\t[1, 2, 3, 4, 5, 8, 6, 0, 7]\t[1, 0, 3, 4, 5, 8, 2, 6, 7]\n",
      "\n",
      "Algorithm     Depth  Nodes     EBF          Depth     Nodes     EBF          Depth     Nodes     EBF\n",
      "IDS\t\t0\t0\t0.000\t\t3\t43\t3.086\t\t11\t225850\t2.954\n",
      "A*h1\t\t0\t0\t0.000\t\t3\t116\t4.488\t\t11\t643246\t3.263\n",
      "A*h2\t\t0\t0\t0.000\t\t3\t51\t3.297\t\t11\t100046\t2.733\n",
      "A*h3\t\t0\t0\t0.000\t\t3\t9\t1.578\t\t11\t1172\t1.762\n"
     ]
    }
   ],
   "source": [
    "goal1=[1, 2, 3, 4, 0, 5, 6, 7, 8]\n",
    "goal2=[1, 2, 3, 4, 5, 8, 6, 0, 7]\n",
    "goal3=[1, 0, 3, 4, 5, 8, 2, 6, 7]\n",
    "runExperiment(goal1,goal2,goal3,[h1_8p,h2_8p,h3_8p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of above table.\n",
    "\n",
    "The above function is the implementation of `runExperiment` function which takes three goalStates as input along with the list of three heuristic functions. Internally, the code runs the `iterativeDeependingSearch` and nodes the depth, nodes returned by the function and compute its effective branching factor. Similarly `aStartSearch` is also called for three different heuristics functions to get the corresponding number of nodes, depth of search and the effective branching factor. We can see if the `goalState` and `startState` are similar, all the functions returned 0 for nodes, depth and effective branching factor. However if we pass the second `goalState` to all of them, we see there is considerable improvement in `aStartSearch` with better heuristic function. The IDS explores 43 nodes to depth of 3 with an effective branching factor of 3.086 while the `aStartSearch` sturggled with h1_8p (which is a poor heuristics that returns 0) to get to the final result with 116 explored nodes and 4.488 effective branching factor. Additionally, when the heuristics function gets better in predicting the cost to reach the goal the goal was achieved quickly with less effective branching factor. We can see from the table above that for the third heuristic function, the `aStarSearch` gets to the goal by expanding only 9 nodes with an effective branching factor of 1.578. Similarly, the result is consistent with the third goal state. This explains that if we have better heuristic function which is admissible then the effective branching factor is reduced which means the number of nodes that need to be expanded at each depth decreases and the goal state can be reached faster.  \n",
    "\n",
    "### Is h3_8p admissible?\n",
    "\n",
    "Yes, the third heuristic function is admissible as it never overestimates the cost to reach the goal state. Let's take few examples to demonstrate the cost to reach the goal estimated by the thrid heuristics.\n",
    "\n",
    "    startState = [1, 2, 3, 4, 0, 5, 6, 7, 8]\n",
    "    goalState1 = [1, 2, 3, 4, 0, 5, 6, 7, 8]\n",
    "    goalState2 = [1, 2, 3, 4, 5, 8, 6, 0, 7]\n",
    "    goalState3 = [1, 0, 3, 4, 5, 8, 2, 6, 7]\n",
    "    \n",
    "If we take goalState1 and pass it to the h3 to find the number of steps that would lead to the goal state, the h3 computes the Manhattan distance of the misplaced tiles. Since, there are no misplaced tiles the h3 returns 0 as its output and which is exactly the number of state to reach the goal. This is a perfect estimation as seen below.\n",
    "Similarly, if we consider the goalState2 we see the estimated steps to reach the goal is 4 which is the sum of all the steps required to swipe the tiles to the goal position. \n",
    "\n",
    "    Sum = 1 (steps to swipe 5 to its goal position) + 1 ( Steps to swipe 8 to its goal position) + 1 (steps to swipe 7 to its goal position) =3\n",
    "\n",
    "If we try to get the number of steps to reach the goal we can see the shortest path to reach the goal is:\n",
    "    \n",
    "    Solution Path to [1, 2, 3, 4, 5, 8, 6, 0, 7]:  [[1, 2, 3, 4, 0, 5, 6, 7, 8], [1, 2, 3, 4, 5, 0, 6, 7, 8], [1, 2, 3, 4, 5, 8, 6, 7, 0], [1, 2, 3, 4, 5, 8, 6, 0, 7]]. \n",
    "    \n",
    "As we can see in the result the number of transition required from the startState to reach the goalState1 is 3 which was what estimated by the heuristic function. We are luck to get the estimate accurately again. \n",
    "Now let's consider the third goal and we see the h3_8p estimates 7 steps to reach the goal. Now if we try to expand the result and see what are the steps to reach the goal through the startState we see there are 11 steps required to reach the goal. The function does not overestimates in this case as well.\n",
    "    \n",
    "    Solution path to goalState3: [[1, 2, 3, 4, 0, 5, 6, 7, 8], [1, 0, 3, 4, 2, 5, 6, 7, 8], [0, 1, 3, 4, 2, 5, 6, 7, 8], [4, 1, 3, 0, 2, 5, 6, 7, 8], [4, 1, 3, 2, 0, 5, 6, 7, 8], [4, 1, 3, 2, 5, 0, 6, 7, 8], [4, 1, 3, 2, 5, 8, 6, 7, 0], [4, 1, 3, 2, 5, 8, 6, 0, 7], [4, 1, 3, 2, 5, 8, 0, 6, 7], [4, 1, 3, 0, 5, 8, 2, 6, 7], [0, 1, 3, 4, 5, 8, 2, 6, 7], [1, 0, 3, 4, 5, 8, 2, 6, 7]]\n",
    "    \n",
    "Lets check for the estimate for the second state found in the solution path [1, 0, 3, 4, 2, 5, 6, 7, 8] we get the estimate of 6 which is again lower than the total cost required to reach the goal i.e. 10. Finally, if we check the heuristic to estimate the cost to reach the goal via  [4, 1, 3, 0, 5, 8, 2, 6, 7], we find the estimate to be 2 (as shown below) which is again an exact cost to reach the goal. \n",
    "    \n",
    "Hence, there are no state to which this function over-estimates. Since the heuristic to be admissible, it has been defined to never over-estimate.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startState = [1, 2, 3, 4, 0, 5, 6, 7, 8]\n",
    "goalState1 = [1, 2, 3, 4, 0, 5, 6, 7, 8]\n",
    "h3_8p(startState,goalState1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goalState2 = [1, 2, 3, 4, 5, 8, 6, 0, 7]\n",
    "h3_8p(startState,goalState2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goalState3 = [1, 0, 3, 4, 5, 8, 2, 6, 7]\n",
    "h3_8p(startState,goalState3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startState=[1, 0, 3, 4, 2, 5, 6, 7, 8]\n",
    "h3_8p(startState,goalState3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startState=[4, 1, 3, 0, 5, 8, 2, 6, 7]\n",
    "h3_8p(startState,goalState3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some example output for the ebf function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.66015625"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest argument values should be a depth of 0, and 1 node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The above examples shows that the effective branching factor with 2 nodes and 1 depth is 1.0. The algorithm finds the solution for this problem exactly with no error at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(2, 1, precision=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.275596989435144"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(200000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.234819248452368"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(200000, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple example using the usual simple graph search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def actionsF_simple(state):\n",
    "    succs = {'a': ['b', 'c'], 'b':['e', 'f', 'g'], 'b':['a'], 'c':['h'], 'h':['i'], 'i':['j', 'k', 'l'], 'k':['z']}\n",
    "    return [(s, 1) for s in succs.get(state, [])]\n",
    "\n",
    "def takeActionF_simple(state, action):\n",
    "    return action\n",
    "\n",
    "def goalTestF_simple(state, goal):\n",
    "    return state == goal\n",
    "\n",
    "def h_simple(state, goal):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 1), ('c', 1)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = actionsF_simple('a')\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('b', 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "takeActionF_simple('a', actions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goalTestF_simple('a', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_simple('a', 'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'c', 'h', 'i', 'k', 'z']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterativeDeepeningSearch('a', 'z', actionsF_simple, takeActionF_simple, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 'c', 'h', 'i', 'k', 'z'], 5)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aStarSearch('a',actionsF_simple, takeActionF_simple,\n",
    "            lambda s: goalTestF_simple(s, 'z'),\n",
    "            lambda s: h_simple(s, 'z'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [A3grader.tar](http://www.cs.colostate.edu/~anderson/cs440/notebooks/A3grader.tar) and extract A3grader.py from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing actionsF_8p([1, 2, 3, 4, 5, 6, 7, 0, 8])\n",
      "\n",
      "--- 5/5 points. Your actionsF_8p correctly returned [('left', 1), ('right', 1), ('up', 1)]\n",
      "\n",
      "Testing takeActionF_8p([1, 2, 3, 4, 5, 6, 7, 0, 8], (up, 1))\n",
      "\n",
      "--- 5/5 points. Your takeActionsF_8p correctly returned ([1, 2, 3, 4, 0, 6, 7, 5, 8], 1)\n",
      "\n",
      "Testing goalTestF_8p([1, 2, 3, 4, 5, 6, 7, 0, 8], [1, 2, 3, 4, 5, 6, 7, 0, 8])\n",
      "\n",
      "--- 5/5 points. Your goalTestF_8p correctly True\n",
      "\n",
      "Testing aStarSearch([1, 2, 3, 4, 5, 6, 7, 0, 8],\n",
      "                     actionsF_8p, takeActionF_8p,\n",
      "                     lambda s: goalTestF_8p(s, [0, 2, 3, 1, 4,  6, 7, 5, 8]),\n",
      "                     lambda s: h1_8p(s, [0, 2, 3, 1, 4,  6, 7, 5, 8]))\n",
      "\n",
      "--- 20/20 points. Your search correctly returned ([[1, 2, 3, 4, 5, 6, 7, 0, 8], [1, 2, 3, 4, 0, 6, 7, 5, 8], [1, 2, 3, 0, 4, 6, 7, 5, 8], [0, 2, 3, 1, 4, 6, 7, 5, 8]], 3)\n",
      "\n",
      "Testing iterativeDeepeningSearch([5, 2, 8, 0, 1, 4, 3, 7, 6], \n",
      "                                 [0, 2, 3, 1, 4,  6, 7, 5, 8],\n",
      "                                 actionsF_8p, takeActionF_8p, 10)\n",
      "\n",
      "--- 15/15 points. Your search correctly returned cutoff\n",
      "\n",
      "notebook Grade is 50/50\n"
     ]
    }
   ],
   "source": [
    "%run -i A3grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
